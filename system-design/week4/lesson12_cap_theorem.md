# Week 4, Lesson 12: CAP Theorem Explained Simply

## Table of Contents
- [The Distributed Systems Dilemma](#the-distributed-systems-dilemma)
- [What is the CAP Theorem?](#what-is-the-cap-theorem)
  - [C - Consistency](#c---consistency)
  - [A - Availability](#a---availability)
  - [P - Partition Tolerance](#p---partition-tolerance)
- [Why Can't We Have All Three?](#why-cant-we-have-all-three)
  - [The Network Partition Scenario](#the-network-partition-scenario)
  - [The Impossible Choice](#the-impossible-choice)
- [CP vs AP Systems](#cp-vs-ap-systems)
  - [CP Systems: Choose Consistency](#cp-systems-choose-consistency)
  - [AP Systems: Choose Availability](#ap-systems-choose-availability)
- [Real-World Examples](#real-world-examples)
  - [Banking Systems (CP)](#banking-systems-cp)
  - [Social Media (AP)](#social-media-ap)
  - [E-commerce (Mixed)](#e-commerce-mixed)
- [CAP in Popular Databases](#cap-in-popular-databases)
  - [CP Databases](#cp-databases)
  - [AP Databases](#ap-databases)
  - [Tunable Consistency](#tunable-consistency)
- [Beyond CAP: The PACELC Theorem](#beyond-cap-the-pacelc-theorem)
- [Consistency Models Spectrum](#consistency-models-spectrum)
  - [Strong Consistency](#strong-consistency)
  - [Eventual Consistency](#eventual-consistency)
  - [Causal Consistency](#causal-consistency)
  - [Read-Your-Writes Consistency](#read-your-writes-consistency)
- [Designing with CAP in Mind](#designing-with-cap-in-mind)
  - [Questions to Ask](#questions-to-ask)
  - [Hybrid Approaches](#hybrid-approaches)
- [Common Misconceptions](#common-misconceptions)
- [Key Concepts to Remember](#key-concepts-to-remember)
- [Practice Questions](#practice-questions)
- [Next Up](#next-up)

---

Welcome to the final lesson of Week 4! We're concluding our distribution fundamentals with the **CAP Theorem** - one of the most important concepts in distributed systems. Understanding CAP helps you make informed trade-offs when designing systems.

---

## The Distributed Systems Dilemma

When you have data on multiple servers, a fundamental problem arises:

```
Single Server (Easy):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Server    â”‚
â”‚  balance:   â”‚
â”‚   $1000     â”‚  â† One source of truth
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Distributed System (Hard):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Server A   â”‚         â”‚  Server B   â”‚
â”‚  balance:   â”‚         â”‚  balance:   â”‚
â”‚   $1000     â”‚         â”‚   $1000     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†‘                       â†‘
       â””â”€â”€â”€â”€â”€ Must stay in sync! â”€â”€â”€â”€â”€â”˜

What happens when:
- User withdraws $100 from Server A
- Network between A and B fails
- Another user checks balance on Server B

Does Server B show $1000 (stale) or refuse to answer?
```

This is the core dilemma that CAP theorem addresses.

---

## What is the CAP Theorem?

The CAP Theorem (proposed by Eric Brewer in 2000) states:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   A distributed system can provide at most TWO of these    â”‚
â”‚   three guarantees simultaneously:                          â”‚
â”‚                                                             â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚         â”‚   Consistency     â”‚                               â”‚
â”‚         â”‚       (C)         â”‚                               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                  â•± â•²                                        â”‚
â”‚                 â•±   â•²                                       â”‚
â”‚                â•±     â•²                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚   â”‚Availabilityâ”‚       â”‚ Partition â”‚                        â”‚
â”‚   â”‚    (A)    â”‚       â”‚ Tolerance â”‚                        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚    (P)    â”‚                        â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                             â”‚
â”‚   Pick TWO: CA, CP, or AP                                  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### C - Consistency

**Every read receives the most recent write or an error.**

```
Consistent System:

Time 0: Balance = $1000 on all nodes
Time 1: User withdraws $100 from Node A
Time 2: Any node you ask gives $900

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node A  â”‚     â”‚ Node B  â”‚     â”‚ Node C  â”‚
â”‚  $900   â”‚     â”‚  $900   â”‚     â”‚  $900   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†‘
              Ask any node
              Same answer: $900
```

```
Inconsistent System:

Time 0: Balance = $1000 on all nodes
Time 1: User withdraws $100 from Node A
Time 2: Node A has $900, others still show $1000!

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node A  â”‚     â”‚ Node B  â”‚     â”‚ Node C  â”‚
â”‚  $900   â”‚     â”‚  $1000  â”‚     â”‚  $1000  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†‘               â†‘
  Updated        Stale data!
```

**Key point:** Consistency means all nodes see the same data at the same time.

### A - Availability

**Every request receives a response (not an error), without guarantee it's the most recent data.**

```
Available System:

User sends request â†’ System responds (always)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User   â”‚ â”€â”€â”€â”€â”€â”€â–º  â”‚ System  â”‚ â”€â”€â”€â”€â”€â”€â–º Response!
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Even if:
- Some nodes are down
- Network is slow
- Data might be stale

The system ALWAYS responds.
```

```
Unavailable System:

User sends request â†’ Error or timeout

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User   â”‚ â”€â”€â”€â”€â”€â”€â–º  â”‚ System  â”‚ â”€â”€â”€â”€â”€â”€â–º "Service Unavailable"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                     Can't guarantee
                     correct answer,
                     so refuses to answer
```

**Key point:** Availability means the system always responds, even during failures.

### P - Partition Tolerance

**The system continues to operate despite network partitions.**

```
Network Partition:

Normal:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â—„â”€â”€â”€â”€â”€â”€â”€â”€â–º â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node A  â”‚   network  â”‚ Node B  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Partitioned (network failure):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     âœ—      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node A  â”‚ â—„â”€â”€â”€â”€â”€â”€â–º   â”‚ Node B  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   broken   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Nodes can't communicate!
But system must still work.
```

**Real partition causes:**
- Network cable cut
- Router failure
- Datacenter network issues
- Cloud provider problems
- Firewall misconfiguration

**Key point:** Partition tolerance means surviving network failures between nodes.

---

## Why Can't We Have All Three?

### The Network Partition Scenario

Let's walk through why you must choose:

```
Setup: Two nodes, both have balance = $1000

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Node A    â”‚ â—„â”€â”€â”€â”€â”€ Network â”€â”€â”€â–ºâ”‚   Node B    â”‚
â”‚ balance:    â”‚                    â”‚ balance:    â”‚
â”‚   $1000     â”‚                    â”‚   $1000     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Step 1: Network partition occurs**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        âœ—          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Node A    â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   â”‚   Node B    â”‚
â”‚   $1000     â”‚    PARTITION!     â”‚   $1000     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Nodes can no longer communicate!
```

**Step 2: Write request arrives at Node A**

```
User: "Withdraw $100 from my account"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        âœ—          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Node A    â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   â”‚   Node B    â”‚
â”‚   $1000     â”‚                   â”‚   $1000     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â–²
      â”‚
    User: "Withdraw $100"
```

### The Impossible Choice

Now Node A has two options:

**Option 1: Be Consistent (CP) - Reject the write**

```
Node A: "I can't sync with Node B, so I'll refuse this request"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        âœ—          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Node A    â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   â”‚   Node B    â”‚
â”‚   $1000     â”‚                   â”‚   $1000     â”‚
â”‚   LOCKED    â”‚                   â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
   User: "Error: Service unavailable"

âœ… Consistent: Both nodes agree ($1000)
âŒ Not Available: User's request rejected
âœ… Partition Tolerant: System handled the partition
```

**Option 2: Be Available (AP) - Accept the write**

```
Node A: "I'll process this even without syncing to B"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        âœ—          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Node A    â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   â”‚   Node B    â”‚
â”‚   $900      â”‚                   â”‚   $1000     â”‚
â”‚  (updated)  â”‚                   â”‚   (stale)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
   User: "Success! Balance: $900"

âŒ Not Consistent: Nodes disagree ($900 vs $1000)
âœ… Available: User's request succeeded
âœ… Partition Tolerant: System handled the partition
```

**Why not CA (Consistent + Available)?**

```
CA would mean:
- Always consistent (all nodes agree)
- Always available (always respond)
- BUT: Can't handle partitions

This only works if you guarantee NO network failures.

In distributed systems, network partitions WILL happen.
So you MUST be partition tolerant.

CA is essentially a single-node system!
```

**The real choice is: CP or AP?**

---

## CP vs AP Systems

### CP Systems: Choose Consistency

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CP System Behavior                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  During normal operation:                                   â”‚
â”‚  âœ… Consistent                                              â”‚
â”‚  âœ… Available                                               â”‚
â”‚                                                             â”‚
â”‚  During network partition:                                  â”‚
â”‚  âœ… Consistent (refuse stale reads/writes)                  â”‚
â”‚  âŒ Available (some requests fail)                          â”‚
â”‚                                                             â”‚
â”‚  Philosophy: "Better to give no answer than wrong answer"   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Use CP when:**
- Data accuracy is critical
- Wrong data causes serious problems
- Users prefer errors over incorrect info

**Examples:**
- Bank account balances
- Inventory counts (prevent overselling)
- Distributed locks
- Configuration management

**CP Databases:**
- MongoDB (with majority write concern)
- HBase
- Redis Cluster
- Zookeeper
- Consul

### AP Systems: Choose Availability

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AP System Behavior                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  During normal operation:                                   â”‚
â”‚  âœ… Consistent (eventually)                                 â”‚
â”‚  âœ… Available                                               â”‚
â”‚                                                             â”‚
â”‚  During network partition:                                  â”‚
â”‚  âŒ Consistent (nodes may have different data)              â”‚
â”‚  âœ… Available (always respond)                              â”‚
â”‚                                                             â”‚
â”‚  Philosophy: "Better to give stale answer than no answer"   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Use AP when:**
- Availability is critical
- Stale data is acceptable temporarily
- System must always respond

**Examples:**
- Social media feeds
- Product catalogs
- DNS
- Shopping carts
- Session stores

**AP Databases:**
- Cassandra
- DynamoDB
- CouchDB
- Riak

---

## Real-World Examples

### Banking Systems (CP)

```
Why banks choose Consistency over Availability:

Scenario: User has $100, tries to withdraw $100 twice

AP System (BAD for banks):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     Partition     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ATM A   â”‚ â—„â”€â”€â”€â”€â”€â”€â”€âœ—â”€â”€â”€â”€â”€â”€â”€â–º â”‚ ATM B   â”‚
â”‚ $100    â”‚                   â”‚ $100    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                              â”‚
  Withdraw                      Withdraw
   $100                          $100
     â”‚                              â”‚
     â–¼                              â–¼
   "Success"                    "Success"
   ($0 left)                    ($0 left)

Result: Bank gave out $200 from $100 account! ğŸ’¸

CP System (GOOD for banks):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     Partition     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ATM A   â”‚ â—„â”€â”€â”€â”€â”€â”€â”€âœ—â”€â”€â”€â”€â”€â”€â”€â–º â”‚ ATM B   â”‚
â”‚ $100    â”‚                   â”‚ $100    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                              â”‚
  Withdraw                      Withdraw
   $100                          $100
     â”‚                              â”‚
     â–¼                              â–¼
   "Success"                   "Error:
   ($0 left)                    Cannot process,
                                try again later"

Result: Only $100 withdrawn, data consistent! âœ…
```

### Social Media (AP)

```
Why Twitter/Facebook choose Availability:

Scenario: Celebrity posts tweet, network partition occurs

CP System (BAD for social media):
User in Europe: "Error: Cannot load feed"
User in Asia: "Error: Cannot load feed"

Millions of users see errors!
Terrible user experience.

AP System (GOOD for social media):
User in Europe: Sees feed (maybe missing latest tweet)
User in Asia: Sees feed (maybe missing latest tweet)

Everyone can use the app!
Tweet will appear once partition heals.

Trade-off:
- User might see 999 likes instead of 1000
- User might not see newest post for a few seconds
- Much better than showing error!
```

### E-commerce (Mixed)

```
Smart e-commerce uses BOTH:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    E-commerce Architecture                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Product Catalog: AP                                        â”‚
â”‚  - Always show products                                     â”‚
â”‚  - Price might be slightly stale                            â”‚
â”‚  - Better than empty page!                                  â”‚
â”‚                                                             â”‚
â”‚  Shopping Cart: AP                                          â”‚
â”‚  - Always let users add items                               â”‚
â”‚  - Sync when possible                                       â”‚
â”‚  - Don't lose sales!                                        â”‚
â”‚                                                             â”‚
â”‚  Checkout/Payment: CP                                       â”‚
â”‚  - Must have accurate inventory                             â”‚
â”‚  - Must process payment correctly                           â”‚
â”‚  - Okay to show "try again" on failure                      â”‚
â”‚                                                             â”‚
â”‚  Reviews: AP                                                â”‚
â”‚  - Show reviews even if slightly stale                      â”‚
â”‚  - New review might take seconds to appear                  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## CAP in Popular Databases

### CP Databases

| Database | How it achieves CP |
|----------|-------------------|
| **MongoDB** | Majority write concern requires acknowledgment from majority of nodes |
| **HBase** | Single master for writes, strong consistency |
| **Zookeeper** | Consensus protocol (ZAB), leader-based |
| **etcd** | Raft consensus, linearizable reads |
| **Redis Cluster** | Stops writes if can't reach majority |

```
MongoDB with Majority Write Concern:

Write "balance: $900"
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Primary   â”‚ â”€â”€â–º Write to primary
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Secondary 1 â”‚ â”‚ Secondary 2 â”‚ â”‚ Secondary 3 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
          2 of 3 ACK
               â”‚
               â–¼
        "Write successful"

If can't reach majority â†’ Write fails (CP behavior)
```

### AP Databases

| Database | How it achieves AP |
|----------|-------------------|
| **Cassandra** | Tunable consistency, can read/write with single node |
| **DynamoDB** | Eventually consistent reads by default |
| **CouchDB** | Multi-master replication, conflict resolution |
| **Riak** | Vector clocks, sibling resolution |

```
Cassandra with Consistency Level ONE:

Write "balance: $900"
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Node 1    â”‚ â”€â”€â–º Write successful!
â”‚   (any)     â”‚     (immediately returns)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚ (async replication)
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Node 2    â”‚ â”‚   Node 3    â”‚ â”‚   Node 4    â”‚
â”‚ (eventually)â”‚ â”‚ (eventually)â”‚ â”‚ (eventually)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Write succeeds even if other nodes unreachable (AP behavior)
```

### Tunable Consistency

Many modern databases let you choose per-operation:

```
Cassandra Consistency Levels:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Level        â”‚ Behavior                      â”‚ CAP        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ONE           â”‚ 1 node responds               â”‚ AP         â”‚
â”‚ QUORUM        â”‚ Majority responds             â”‚ CP         â”‚
â”‚ ALL           â”‚ All nodes respond             â”‚ Strong CP  â”‚
â”‚ LOCAL_QUORUM  â”‚ Majority in local datacenter  â”‚ Regional   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Example:
// Fast, eventually consistent read (AP)
SELECT * FROM users WHERE id = 123;
CONSISTENCY ONE;

// Strong consistent read (CP)
SELECT * FROM users WHERE id = 123;
CONSISTENCY QUORUM;
```

```
DynamoDB Consistency Options:

// Eventually consistent (default, faster, cheaper)
dynamodb.get_item(
    TableName='Users',
    Key={'user_id': '123'},
    ConsistentRead=False  # AP
)

// Strongly consistent (slower, costs more)
dynamodb.get_item(
    TableName='Users',
    Key={'user_id': '123'},
    ConsistentRead=True   # CP
)
```

---

## Beyond CAP: The PACELC Theorem

CAP only describes behavior during partitions. PACELC extends this:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PACELC Theorem                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  IF there's a Partition (P):                                â”‚
â”‚      Choose between Availability (A) and Consistency (C)    â”‚
â”‚                                                             â”‚
â”‚  ELSE (normal operation):                                   â”‚
â”‚      Choose between Latency (L) and Consistency (C)         â”‚
â”‚                                                             â”‚
â”‚  Full form: PAC / ELC                                       â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why this matters:**

```
During partition: CP vs AP (as CAP says)

During NORMAL operation (no partition):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚  Strong Consistency:                                        â”‚
â”‚  Write â†’ Sync to all nodes â†’ Return                        â”‚
â”‚  Latency: 50-200ms (must wait for sync)                    â”‚
â”‚                                                             â”‚
â”‚  Eventual Consistency:                                      â”‚
â”‚  Write â†’ Return immediately â†’ Async sync                   â”‚
â”‚  Latency: 5-20ms (no waiting)                              â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Even without partitions, there's a consistency/latency trade-off!
```

**Database classification with PACELC:**

| Database | P+A/C | E+L/C | Meaning |
|----------|-------|-------|---------|
| Cassandra | PA | EL | Favors availability and low latency |
| DynamoDB | PA | EL | Same as Cassandra |
| MongoDB | PC | EC | Favors consistency always |
| MySQL (async) | PA | EL | Availability and speed |
| MySQL (sync) | PC | EC | Consistency always |

---

## Consistency Models Spectrum

Consistency isn't binary. There's a spectrum:

```
Strong â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Weak

Linearizable â†’ Sequential â†’ Causal â†’ Read-your-writes â†’ Eventual
     â”‚              â”‚           â”‚            â”‚              â”‚
 Strictest      Ordered     Logical      Practical      Loosest
                           ordering       minimum
```

### Strong Consistency

```
Linearizable (Strictest):
- Operations appear instantaneous
- Global ordering of all operations
- If write completes, all subsequent reads see it

Timeline:
T1: Write X=1       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
T2:                      Read X â†’ Must return 1
T3:                                   Read X â†’ Must return 1

Used in: Zookeeper, etcd, Spanner
Cost: High latency, lower availability
```

### Eventual Consistency

```
Eventually Consistent (Loosest):
- Updates propagate eventually
- No ordering guarantees
- Reads may return stale data

Timeline:
T1: Write X=1 to Node A   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
T2:     Read X from Node B â†’ May return old value!
T3:               Read X from Node B â†’ Eventually returns 1

Used in: DNS, Cassandra (default), DynamoDB (default)
Cost: Low latency, high availability
```

### Causal Consistency

```
Causal Consistency (Middle ground):
- Causally related operations are ordered
- Unrelated operations may be seen in any order

Example:
Alice posts: "I got the job!" (Post A)
Alice comments: "So excited!" (Comment B, caused by A)

Causal consistency guarantees:
- If you see Comment B, you must have seen Post A
- You won't see "So excited!" without "I got the job!"

Used in: MongoDB (causal sessions), CockroachDB
```

### Read-Your-Writes Consistency

```
Read-Your-Writes:
- You always see your own writes
- Others may not see them yet

User Alice:
Write "profile_pic = cat.jpg"    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
Read profile                      â†’ Always sees cat.jpg âœ“

User Bob (same time):
Read Alice's profile              â†’ May still see old pic

Used in: Most web apps (via sticky sessions or read-after-write)
Practical minimum for good UX.
```

---

## Designing with CAP in Mind

### Questions to Ask

```
1. What happens if we show stale data?
   - Annoying but okay â†’ Consider AP
   - Dangerous/costly â†’ Must be CP

2. What happens if service is unavailable?
   - Users wait and retry â†’ CP is okay
   - Users leave forever â†’ Need AP

3. How often do partitions occur?
   - Rarely (single datacenter) â†’ Less critical
   - Frequently (global) â†’ Very important

4. Can we make it right later?
   - Yes (compensating transactions) â†’ AP with reconciliation
   - No (can't un-send email) â†’ Need CP for that operation

5. What's our SLA?
   - 99.99% uptime required â†’ AP with eventual consistency
   - Correctness > availability â†’ CP acceptable
```

### Hybrid Approaches

**Approach 1: Different consistency per operation**

```python
class UserService:
    def update_email(self, user_id, email):
        # CP: Email must be consistent (used for auth)
        self.db.write(
            consistency='QUORUM',
            data={'email': email}
        )

    def update_profile_bio(self, user_id, bio):
        # AP: Bio can be eventually consistent
        self.db.write(
            consistency='ONE',
            data={'bio': bio}
        )
```

**Approach 2: Write-ahead log for eventual consistency**

```
User places order â†’ Write to local DB â†’ Queue for sync

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Region A      â”‚        â”‚   Region B      â”‚
â”‚                 â”‚        â”‚                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Order: 123  â”‚ â”‚â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ â”‚ Order: 123  â”‚ â”‚
â”‚ â”‚ (immediate) â”‚ â”‚ async  â”‚ â”‚ (eventual)  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User sees order immediately (AP)
Globally consistent eventually
Reconciliation handles conflicts
```

**Approach 3: CRDTs for automatic conflict resolution**

```
CRDT = Conflict-free Replicated Data Type

Example: Counter that can increment on any node

Node A: counter = 5, increment â†’ 6
Node B: counter = 5, increment â†’ 6

Traditional: CONFLICT! 6 vs 6, which is right?

CRDT approach:
Node A: {A: 1} increments â†’ {A: 2}
Node B: {B: 1} increments â†’ {B: 2}
Merged: {A: 2, B: 2} â†’ total = 4

No conflicts! Both increments preserved.

Used in: Riak, Redis CRDT, collaborative editing
```

---

## Common Misconceptions

### Misconception 1: "You must choose two, can't have all three"

```
Misleading because:
- During NORMAL operation, you can have all three!
- The choice only matters during PARTITIONS
- Partitions are temporary, not permanent

Reality:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Normal: C + A + P (sort of)                                â”‚
â”‚  - Consistent reads                                         â”‚
â”‚  - Available                                                â”‚
â”‚  - No partition happening, so P is trivial                  â”‚
â”‚                                                             â”‚
â”‚  Partition: Must choose C or A                              â”‚
â”‚  - P is forced upon you                                     â”‚
â”‚  - Decide: errors (C) or stale data (A)?                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Misconception 2: "CA systems exist"

```
NOT in distributed systems!

CA would mean:
- Consistent
- Available
- NOT partition tolerant

But in a distributed system, partitions WILL happen.
If you can't handle partitions, you're not distributed.

"CA" systems are really:
- Single-node databases
- Or systems that become unavailable during partitions
```

### Misconception 3: "AP means inconsistent forever"

```
AP systems are EVENTUALLY consistent, not NEVER consistent.

Timeline:
T0: Partition occurs
T1: Writes go to different nodes (inconsistent)
T2: Partition heals
T3: Nodes sync up
T4: Consistency restored!

AP doesn't mean "wrong data forever"
It means "temporarily stale, eventually correct"
```

### Misconception 4: "Consistency = ACID consistency"

```
CAP Consistency â‰  ACID Consistency

CAP Consistency:
- All nodes see same data
- About replication

ACID Consistency:
- Database enforces constraints
- About transactions

They're different concepts with the same word!
```

### Misconception 5: "Latency and availability are the same"

```
They're related but different:

High Latency, Available:
Request â†’ Wait 30 seconds â†’ Response
(System responded, just slowly)

Unavailable:
Request â†’ Error/Timeout
(System didn't respond)

A slow response is still available!
But users might not see it that way...

This is why PACELC matters.
```

---

## Key Concepts to Remember

1. **CAP Theorem**: In a distributed system, during a partition, you must choose between Consistency and Availability

2. **Partition Tolerance is mandatory** for distributed systems - partitions will happen

3. **CP systems** reject requests during partitions to stay consistent

4. **AP systems** serve requests during partitions with potentially stale data

5. **The real choice** is what to do when the network fails

6. **Eventual consistency** means data will converge once the partition heals

7. **Most systems are hybrid** - different consistency for different operations

8. **PACELC** extends CAP: Even without partitions, there's a latency/consistency trade-off

9. **Consistency is a spectrum** from linearizable (strongest) to eventual (weakest)

10. **Design for your requirements** - not every operation needs the same consistency level

---

## Practice Questions

**Q1:** A bank is designing a new system for checking account balances. Should they use a CP or AP database? What about for viewing transaction history?

<details>
<summary>View Answer</summary>

**Account Balance: CP (Consistency)**

```
Why CP for balance:

Scenario: User has $100
- ATM A: Shows $100, user decides to withdraw $80
- ATM B (partition): Shows $100, user's spouse withdraws $80

With AP: Both withdrawals succeed â†’ Overdraft! ğŸ’¸
With CP: Second withdrawal fails â†’ "Please try again"

User experience:
- Brief error is acceptable
- Incorrect balance is NOT acceptable (could cause overdrafts)
- Financial accuracy is legally required
```

**Transaction History: AP (Availability)**

```
Why AP for history:

- User wants to see past transactions
- Showing slightly stale history is fine
- Better to show "last 30 transactions" than error
- New transactions can appear with small delay

Trade-off acceptable:
âœ… User can always see their history
âš ï¸ Newest transaction might take 2-3 seconds to appear
âŒ "Service unavailable" error

This is READ-ONLY data - no risk of inconsistent actions
```

**Architecture:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Banking System                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Balance Service (CP)          History Service (AP)         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ PostgreSQL          â”‚      â”‚ Cassandra           â”‚      â”‚
â”‚  â”‚ Synchronous         â”‚      â”‚ Eventually          â”‚      â”‚
â”‚  â”‚ Replication         â”‚      â”‚ Consistent          â”‚      â”‚
â”‚  â”‚                     â”‚      â”‚                     â”‚      â”‚
â”‚  â”‚ Operations:         â”‚      â”‚ Operations:         â”‚      â”‚
â”‚  â”‚ - Check balance     â”‚      â”‚ - View history      â”‚      â”‚
â”‚  â”‚ - Withdraw          â”‚      â”‚ - Search trans.     â”‚      â”‚
â”‚  â”‚ - Transfer          â”‚      â”‚ - Download statementâ”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</details>

**Q2:** During a network partition between two datacenters, your CP database stops accepting writes. Users are angry. Your boss asks "Why can't we just accept the writes and fix inconsistencies later?" What's your response?

<details>
<summary>View Answer</summary>

**Short Answer:**

"We could, but the inconsistencies might be unfixable, and the damage could be worse than temporary unavailability."

**Detailed Explanation:**

```
Scenario: E-commerce during partition

Datacenter A (New York)         Datacenter B (London)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Inventory: 1 item   â”‚    âœ—    â”‚ Inventory: 1 item   â”‚
â”‚                     â”‚ PARTITIONâ”‚                     â”‚
â”‚ Customer 1: "Buy"   â”‚         â”‚ Customer 2: "Buy"   â”‚
â”‚ â†’ Inventory: 0      â”‚         â”‚ â†’ Inventory: 0      â”‚
â”‚ â†’ Order confirmed!  â”‚         â”‚ â†’ Order confirmed!  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Partition heals:
- Inventory is now: -1 (IMPOSSIBLE!)
- Two customers paid for ONE item
- Someone doesn't get their product
```

**The "Fix It Later" Problems:**

```
1. Some inconsistencies can't be fixed:
   - Both customers charged â†’ Must refund one
   - But who? First customer? Random?
   - One customer gets angry email: "Sorry, we oversold"
   - Legal issues, reputation damage

2. Compensation is expensive:
   - Refund processing fees
   - Customer service time
   - Potential lawsuits
   - Lost customer trust

3. Some operations are irreversible:
   - Sent emails can't be unsent
   - Triggered webhooks to partners
   - Started physical fulfillment
   - Notified downstream systems

4. Reconciliation is complex:
   - Which write wins?
   - Need conflict resolution logic
   - Edge cases everywhere
   - Developer time to build and maintain
```

**When AP Actually Works:**

```
If your data CAN be reconciled:

âœ… Like counts: Just add them up
âœ… User preferences: Last write wins (usually fine)
âœ… Shopping cart: Merge items from both sides
âœ… Comments: Include all, sort by timestamp

But inventory/financial data:
âŒ Can't create items out of thin air
âŒ Can't double-spend money
âŒ Business rules prevent merging
```

**Recommended Response to Boss:**

```
"We have two options:

Option A (Current - CP):
- Writes fail during partition
- ~5 minutes of errors per year
- Zero data inconsistencies
- No angry 'we oversold' emails

Option B (AP with reconciliation):
- Writes always succeed
- But we'll sometimes oversell
- Need refund process
- Customer service cost: $X per incident
- Reputation risk

For inventory/payments, Option A is safer.
For non-critical data (reviews, likes), we can switch to AP."
```

</details>

**Q3:** Explain how Cassandra can be configured as either CP or AP depending on consistency level settings. Give examples of when you'd use each.

<details>
<summary>View Answer</summary>

**Cassandra Consistency Levels:**

```
Cassandra has tunable consistency per query:

Replication Factor (RF) = 3 (data on 3 nodes)

Write Consistency Levels:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Level       â”‚ Behavior                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ONE         â”‚ Write to 1 node, return success           â”‚
â”‚ TWO         â”‚ Write to 2 nodes, return success          â”‚
â”‚ QUORUM      â”‚ Write to majority (2 of 3), return successâ”‚
â”‚ ALL         â”‚ Write to all 3 nodes, return success      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Read Consistency Levels:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Level       â”‚ Behavior                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ONE         â”‚ Read from 1 node                          â”‚
â”‚ QUORUM      â”‚ Read from majority, return latest         â”‚
â”‚ ALL         â”‚ Read from all nodes, return latest        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**AP Configuration (High Availability):**

```
Write: ONE
Read: ONE

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Write  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Node 1  â”‚â”€â”€â–º Success! (immediate)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ (async replication)
                         â–¼
                    Nodes 2, 3 (later)

Read:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Read   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Node 2  â”‚â”€â”€â–º May return stale data!
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AP because:
- Writes succeed if ANY node is up
- Reads succeed if ANY node is up
- Data might be inconsistent during partition
```

**When to use AP (ONE/ONE):**

```python
# Time-series metrics (can lose some points)
session.execute(
    "INSERT INTO metrics (ts, value) VALUES (?, ?)",
    consistency_level=ConsistencyLevel.ONE
)

# User activity logs (eventually consistent is fine)
session.execute(
    "INSERT INTO activity_log (user_id, action, ts) VALUES (?, ?, ?)",
    consistency_level=ConsistencyLevel.ONE
)

# Session storage (availability > consistency)
session.execute(
    "SELECT * FROM sessions WHERE session_id = ?",
    consistency_level=ConsistencyLevel.ONE
)
```

**CP Configuration (Strong Consistency):**

```
Write: QUORUM
Read: QUORUM

Formula: R + W > RF guarantees consistency
QUORUM + QUORUM = 2 + 2 = 4 > 3 âœ“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Write  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Node 1  â”‚â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚ Node 2  â”‚â—„â”€â”¤ Must wait for 2 of 3
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚ Node 3  â”‚  â”‚ (optional)
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                  â”‚
                    Success! â—„â”€â”€â”€â”˜

Read:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Read   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Node 1  â”‚â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚ Node 2  â”‚â—„â”€â”¤ Read from 2, compare
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ return latest!
                                  â”‚
                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CP because:
- At least one node in read quorum saw the latest write
- Always returns most recent data
- Fails if majority unavailable (partition)
```

**When to use CP (QUORUM/QUORUM):**

```python
# User balance (must be accurate)
session.execute(
    "UPDATE users SET balance = ? WHERE user_id = ?",
    consistency_level=ConsistencyLevel.QUORUM
)

# Inventory count (prevent overselling)
session.execute(
    "UPDATE products SET stock = ? WHERE product_id = ?",
    consistency_level=ConsistencyLevel.QUORUM
)

# Read balance before allowing purchase
session.execute(
    "SELECT balance FROM users WHERE user_id = ?",
    consistency_level=ConsistencyLevel.QUORUM
)
```

**Mixed Configuration Example:**

```python
class ProductService:
    def update_stock(self, product_id, new_stock):
        # CP: Stock accuracy is critical
        self.session.execute(
            "UPDATE products SET stock = ? WHERE product_id = ?",
            (new_stock, product_id),
            consistency_level=ConsistencyLevel.QUORUM
        )

    def update_description(self, product_id, description):
        # AP: Description can be eventually consistent
        self.session.execute(
            "UPDATE products SET description = ? WHERE product_id = ?",
            (description, product_id),
            consistency_level=ConsistencyLevel.ONE
        )

    def get_product(self, product_id, need_accurate_stock=False):
        cl = ConsistencyLevel.QUORUM if need_accurate_stock else ConsistencyLevel.ONE
        return self.session.execute(
            "SELECT * FROM products WHERE product_id = ?",
            (product_id,),
            consistency_level=cl
        )
```

</details>

**Q4:** A global social media app has users in US, Europe, and Asia. They're deciding between:
- Single database in US (strong consistency)
- Replicas in each region (eventual consistency)

What are the trade-offs? What would you recommend?

<details>
<summary>View Answer</summary>

**Option A: Single Database in US**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Single US Database                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

US Users â”€â”€â”€â”€â”€â–º [US Database] â—„â”€â”€â”€â”€â”€ Europe Users
    5ms              â–²                   150ms
                     â”‚
               Asia Users
                  200ms

Latency:
- US users: ~5ms (local)
- Europe users: ~150ms (cross-Atlantic)
- Asia users: ~200ms (cross-Pacific)
```

**Pros:**
- Strong consistency (one source of truth)
- Simple architecture
- No conflict resolution needed
- Easy to reason about

**Cons:**
- High latency for non-US users
- Single point of failure
- All load on one region
- Poor UX for 60%+ of users

---

**Option B: Regional Replicas (Eventually Consistent)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Multi-Region Architecture                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ US Replica  â”‚â—„â”€â”€â”€â”€â”€â–ºâ”‚Europe Replicâ”‚â—„â”€â”€â”€â”€â”€â–ºâ”‚Asia Replica â”‚
     â”‚             â”‚ async â”‚             â”‚ async â”‚             â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–²                     â–²                     â–²
           â”‚ 5ms                 â”‚ 5ms                 â”‚ 5ms
           â”‚                     â”‚                     â”‚
       US Users            Europe Users           Asia Users

Latency:
- US users: ~5ms
- Europe users: ~5ms
- Asia users: ~5ms
- All users get local performance!
```

**Pros:**
- Low latency for all users
- Regional fault tolerance
- Better user experience
- Load distributed globally

**Cons:**
- Eventually consistent
- Temporary inconsistencies across regions
- Need conflict resolution
- More complex operations

---

**Recommendation: Regional Replicas with Caveats**

For social media, eventual consistency is acceptable:

```
Why it works for social media:

1. Posts/Comments:
   - New post takes 2-3 seconds to appear globally
   - Users don't notice small delays
   - No financial risk

2. Likes/Reactions:
   - Count might be 999 instead of 1000 briefly
   - Converges quickly
   - Nobody cares about exact real-time count

3. Followers:
   - Eventually consistent follower count is fine
   - User won't notice if count updates slowly

4. DMs (special case):
   - Need stronger consistency
   - Use CP for message ordering
   - Or route both users to same region
```

**Hybrid Architecture:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Recommended Architecture                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Public Content (AP - Regional):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ US Region â”‚â—„â”€â”€â”€â–ºâ”‚ EU Region â”‚â—„â”€â”€â”€â–ºâ”‚Asia Regionâ”‚
â”‚ Posts     â”‚asyncâ”‚ Posts     â”‚asyncâ”‚ Posts     â”‚
â”‚ Comments  â”‚     â”‚ Comments  â”‚     â”‚ Comments  â”‚
â”‚ Likes     â”‚     â”‚ Likes     â”‚     â”‚ Likes     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User Account Data (CP - Primary + Replicas):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ US Primaryâ”‚â”€â”€â”€â”€â–ºâ”‚ EU Replicaâ”‚â”€â”€â”€â”€â–ºâ”‚Asia Replicâ”‚
â”‚ Passwords â”‚sync â”‚ Read-only â”‚sync â”‚ Read-only â”‚
â”‚ Email     â”‚     â”‚           â”‚     â”‚           â”‚
â”‚ Settings  â”‚     â”‚           â”‚     â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Direct Messages (CP - Route to User's Region):
User A (US) messages User B (EU)
â†’ Route to EU region (User B's home)
â†’ Strong consistency for message ordering
â†’ User A sees slight latency (acceptable for DMs)
```

**Conflict Resolution Strategy:**

```python
# For posts/comments: Last-Write-Wins with timestamp
def resolve_conflict(version_a, version_b):
    return version_a if version_a.timestamp > version_b.timestamp else version_b

# For likes: CRDT Counter (merge by adding)
def resolve_like_count(region_counts):
    # Each region tracks its own likes
    # Total = sum of all regions
    return sum(region_counts.values())

# For follower lists: Set union
def resolve_followers(sets):
    return set.union(*sets)
```

**Summary:**

| Feature | Consistency | Approach |
|---------|-------------|----------|
| Posts/Feed | Eventual | AP, regional |
| Likes/Comments | Eventual | AP, CRDT |
| User Profile | Eventual | AP, LWW |
| Authentication | Strong | CP, single primary |
| Direct Messages | Strong | CP, routed |
| Payments | Strong | CP, single region |

</details>

**Q5:** Describe a scenario where choosing AP over CP actually results in a worse user experience, despite the system being "available."

<details>
<summary>View Answer</summary>

**Scenario: Airline Seat Selection with AP**

```
Setup:
- Flight has 1 window seat left (14A)
- Two users trying to book simultaneously
- AP system: Always responds, eventually consistent
```

**What Happens with AP:**

```
Time 0: Seat 14A available in both regions

US Region                        EU Region
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Seat 14A: FREE   â”‚            â”‚ Seat 14A: FREE   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                               â”‚
     User A                          User B
  "Select 14A"                    "Select 14A"
        â”‚                               â”‚
        â–¼                               â–¼

Time 1: Both succeed (AP - available!)

US Region                        EU Region
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Seat 14A: USER_A â”‚            â”‚ Seat 14A: USER_B â”‚
â”‚                  â”‚            â”‚                  â”‚
â”‚ "Confirmed! âœ“"   â”‚            â”‚ "Confirmed! âœ“"   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Both users see: "Seat 14A confirmed!"
Both are happy... temporarily.
```

**The Horrible UX:**

```
Time 2: Systems sync, conflict detected

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Conflict Resolution Required!                  â”‚
â”‚                                                             â”‚
â”‚  Option 1: First-write-wins                                 â”‚
â”‚  â†’ User B gets email: "Sorry, your seat was given away"     â”‚
â”‚  â†’ User B now has NO seat (middle seat remaining)           â”‚
â”‚  â†’ User B furious! "It said CONFIRMED!"                     â”‚
â”‚                                                             â”‚
â”‚  Option 2: Last-write-wins                                  â”‚
â”‚  â†’ User A gets email: "Sorry, your seat was given away"     â”‚
â”‚  â†’ Same problem, different victim                           â”‚
â”‚                                                             â”‚
â”‚  Option 3: Random winner                                    â”‚
â”‚  â†’ Someone loses their "confirmed" seat                     â”‚
â”‚  â†’ Completely arbitrary and unfair                          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**User B's Experience:**

```
Timeline:
10:00 - Selected seat 14A
10:00 - "Seat confirmed! âœ“"
10:01 - Showed spouse: "Got the window seat!"
10:30 - Received email: "Booking update"
10:30 - "Your seat has been changed to 22B (middle)"
10:31 - RAGE ğŸ˜¤

User B's perspective:
"The system CONFIRMED my seat!"
"I planned my whole trip around that seat!"
"This is bait-and-switch!"
"I'm never flying this airline again!"
```

**Why CP Would Be Better Here:**

```
With CP:

Time 0: Seat 14A available

User A (first by 50ms)         User B (second by 50ms)
"Select 14A"                   "Select 14A"
     â”‚                              â”‚
     â–¼                              â–¼
Lock acquired âœ“               Lock denied âœ—
"Confirmed!"                  "Sorry, seat taken.
                               Please choose another."

User B's experience:
- Immediate feedback
- Can choose another seat
- No false confirmation
- Disappointed but not deceived
```

**Why AP Failed Here:**

```
AP is bad when:

1. Resources are scarce (one seat, one item)
2. "Confirmation" has meaning to users
3. Rollback causes worse UX than immediate failure
4. Users make decisions based on the response
   (User B told spouse, planned around window seat)

The "availability" was a lie:
- System was "available" to accept booking
- But booking wasn't actually guaranteed
- Delayed failure is worse than immediate failure
```

**Other Scenarios Where AP Hurts UX:**

```
1. Limited inventory flash sales:
   "Order confirmed!" â†’ "Sorry, actually sold out"

2. Event ticket booking:
   "Tickets secured!" â†’ "We oversold, you're waitlisted"

3. Hotel last-room booking:
   "Room confirmed!" â†’ "Actually, you need to find another hotel"

4. Auction bidding:
   "You won!" â†’ "Actually, someone outbid you"

5. Username registration:
   "Username reserved!" â†’ "Actually, someone else got it"
```

**Lesson:**

```
AP is NOT always better user experience.

Consider:
- Is a delayed rejection worse than immediate rejection?
- Does "confirmation" matter to the user?
- Can the user take action based on the confirmation?
- Is there limited inventory/resources?

For scarce resources with meaningful confirmations,
CP provides better UX despite occasional errors.
```

</details>

**Q6:** Your team is building a collaborative document editor (like Google Docs). Analyze the CAP trade-offs for: (1) document content, (2) cursor positions, (3) document permissions.

<details>
<summary>View Answer</summary>

**Overview:**

```
Collaborative Editor Components:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚  1. Document Content                                        â”‚
â”‚     The actual text users are editing                       â”‚
â”‚                                                             â”‚
â”‚  2. Cursor Positions                                        â”‚
â”‚     Where each user's cursor is located                     â”‚
â”‚                                                             â”‚
â”‚  3. Document Permissions                                    â”‚
â”‚     Who can view/edit the document                          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**1. Document Content: AP with CRDTs**

```
Requirement Analysis:
- Users type continuously (high write frequency)
- Must never lose user's typing
- Offline editing should work
- Sync when connection restored
- Conflicts WILL happen (two users edit same line)

Why AP:
- Users expect typing to always work
- "Cannot save" error = unacceptable UX
- Offline mode is essential
- Temporary inconsistency is okay
```

**Implementation with CRDTs:**

```
CRDT: Conflict-free Replicated Data Type

User A types "Hello"        User B types "Hi"
at position 0               at position 0
        â”‚                         â”‚
        â–¼                         â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Hello   â”‚               â”‚ Hi      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ Merge
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ HelloHi      â”‚  (or "HiHello")
            â”‚              â”‚
            â”‚ Both edits   â”‚
            â”‚ preserved!   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CRDTs used:
- RGA (Replicated Growable Array) for text
- Unique IDs per character
- Deterministic merge rules
```

**CAP Choice: AP**
- Available: Always accept edits
- Eventually consistent: Merge on sync
- Partition tolerant: Works offline

---

**2. Cursor Positions: AP with Weak Consistency**

```
Requirement Analysis:
- Shows where other users are editing
- Updates very frequently (every keystroke)
- Stale cursor position is annoying but not critical
- Missing cursor update = minor UX issue
- High volume, low importance

Why AP:
- Not worth blocking for cursor sync
- Stale position is tolerable (user will update soon)
- Loss of cursor updates is okay
```

**Implementation:**

```
Cursor updates via WebSocket:

User A moves cursor
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Broadcast to    â”‚
â”‚ other users     â”‚
â”‚                 â”‚
â”‚ Best-effort     â”‚
â”‚ No ACK required â”‚
â”‚ Fire and forget â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                         â–¼
   User B sees               User C sees
   cursor (maybe)            cursor (maybe)

If message lost:
- Next cursor movement will update
- No need to retry
- At-most-once delivery is fine
```

**CAP Choice: AP (weakest form)**
- Available: Always send updates
- Weakly consistent: May miss updates
- Best-effort delivery

---

**3. Document Permissions: CP**

```
Requirement Analysis:
- Controls who can access document
- Security-critical (wrong permissions = data leak)
- Changes rarely
- Must be accurate

Why CP:
- Incorrect permissions = security breach
- User removed from doc should NOT see content
- Error is better than wrong access
```

**Implementation:**

```
Permission check before any action:

User requests document
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Permission Service  â”‚
â”‚                     â”‚
â”‚ Check: Can user X   â”‚
â”‚ access document Y?  â”‚
â”‚                     â”‚
â”‚ MUST be consistent! â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€ Yes â”€â”€â–º Serve document
        â”‚
        â””â”€â”€ No â”€â”€â–º Access denied
        â”‚
        â””â”€â”€ Error â”€â”€â–º "Please try again"
                      (NOT "here's the doc anyway")

Permission update:
Admin removes User B
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Sync to all nodes   â”‚
â”‚ BEFORE confirming   â”‚
â”‚                     â”‚
â”‚ Write concern: ALL  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
User B's next request â†’ Denied immediately
(Not "denied in a few seconds")
```

**CAP Choice: CP**
- Consistent: All nodes agree on permissions
- Unavailable during partition: Deny access if unsure
- Partition tolerant: Handled by denying

---

**Combined Architecture:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Collaborative Editor Architecture               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Permission Service (CP)                 â”‚   â”‚
â”‚  â”‚  - PostgreSQL with sync replication                 â”‚   â”‚
â”‚  â”‚  - Check on every request                           â”‚   â”‚
â”‚  â”‚  - Deny if partition                                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                  â”‚
â”‚                          â”‚ Auth check                       â”‚
â”‚                          â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚               Document Service (AP)                  â”‚   â”‚
â”‚  â”‚  - CRDT-based content storage                       â”‚   â”‚
â”‚  â”‚  - Accept writes even offline                       â”‚   â”‚
â”‚  â”‚  - Merge on reconnection                            â”‚   â”‚
â”‚  â”‚  - Yjs or Automerge library                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                  â”‚
â”‚                          â”‚ Real-time sync                   â”‚
â”‚                          â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Presence Service (AP-weak)              â”‚   â”‚
â”‚  â”‚  - WebSocket broadcast                              â”‚   â”‚
â”‚  â”‚  - Cursor positions                                 â”‚   â”‚
â”‚  â”‚  - User online status                               â”‚   â”‚
â”‚  â”‚  - Best-effort, no persistence                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Summary Table:**

| Component | CAP | Consistency | Reason |
|-----------|-----|-------------|--------|
| Permissions | CP | Strong | Security-critical |
| Content | AP | Eventual (CRDT) | Must always work, offline support |
| Cursors | AP | Weak | Best-effort, not critical |

</details>

**Q7:** A startup is building a ride-sharing app. During a network partition between their two datacenters, should they continue matching riders with drivers or stop the service? Justify your decision.

<details>
<summary>View Answer</summary>

**Recommendation: Continue service (AP) with safety measures**

**Why AP (Continue Matching):**

```
Business Reality:
- Each minute of downtime = lost revenue
- Drivers go offline if app "doesn't work"
- Riders switch to competitors immediately
- Reputation damage from outage

User Expectations:
- "I need a ride NOW"
- Users don't care about internal partitions
- Error message = open competitor app
- Availability is the core value proposition
```

**The Risk of CP (Stop Service):**

```
Partition occurs (5 minutes):

With CP:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   5:00 PM: Partition starts                                 â”‚
â”‚   5:00 PM: "Cannot request ride at this time"               â”‚
â”‚   5:01 PM: Users open Lyft                                  â”‚
â”‚   5:02 PM: Drivers: "App is broken, switching to Lyft"      â”‚
â”‚   5:05 PM: Partition heals                                  â”‚
â”‚   5:05 PM: "Service restored!" (but users are gone)         â”‚
â”‚                                                             â”‚
â”‚   Cost: Lost rides, lost drivers, reputation damage         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**How to Make AP Safe:**

```
Potential Problem: Double-matching
- Driver matched to Rider A in DC1
- Same driver matched to Rider B in DC2
- Partition heals: driver has 2 rides!

Solution: Regional affinity + conflict resolution

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Ride-Sharing During Partition                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   DC1 (East Coast)              DC2 (West Coast)            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚   â”‚ Drivers: D1-D50 â”‚          â”‚ Drivers: D51-D100â”‚         â”‚
â”‚   â”‚ Match locally   â”‚    âœ—     â”‚ Match locally    â”‚         â”‚
â”‚   â”‚                 â”‚ PARTITION â”‚                  â”‚         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                             â”‚
â”‚   Rule: Each DC matches only LOCAL drivers                  â”‚
â”‚   - D1 (East) can only match in DC1                        â”‚
â”‚   - D51 (West) can only match in DC2                       â”‚
â”‚   - No double-matching possible!                            â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Conflict Resolution for Edge Cases:**

```python
class RideMatchingService:
    def match_rider(self, rider, available_drivers):
        # 1. Only consider drivers in our region
        local_drivers = [d for d in available_drivers
                        if d.home_region == self.region]

        # 2. Create match with unique ID
        match = Match(
            id=generate_uuid(),
            rider=rider,
            driver=best_driver(local_drivers),
            created_at=now(),
            region=self.region
        )

        # 3. Store locally (AP)
        self.local_db.save(match)

        # 4. Queue for sync (when partition heals)
        self.sync_queue.push(match)

        return match

    def resolve_conflicts_after_partition(self):
        # In rare case of double-match (driver changed regions):
        for driver in drivers_with_multiple_matches():
            matches = get_matches_for_driver(driver)

            # Keep earliest match, cancel others
            matches.sort(key=lambda m: m.created_at)
            keep = matches[0]

            for match in matches[1:]:
                cancel_match(match)
                notify_rider(match.rider,
                    "Your driver was reassigned. Finding new driver...")
                rematch_rider(match.rider)  # Priority re-matching
```

**Additional Safety Measures:**

```
1. Driver location updates:
   - Continue tracking driver GPS
   - Store locally during partition
   - Sync after partition heals
   - Rider sees accurate driver position

2. Payment processing:
   - Queue payment for after ride
   - Process when connectivity confirmed
   - Don't lose the charge!

3. Trip state machine:
   - REQUESTED â†’ MATCHED â†’ EN_ROUTE â†’ IN_PROGRESS â†’ COMPLETED
   - Each transition logged locally
   - Reconcile states after partition

4. Monitoring:
   - Alert on partition detection
   - Track match rate during partition
   - Measure conflict rate after heal
   - Learn and improve thresholds
```

**What About Payments? (The CP Part)**

```
Hybrid approach:

Matching & Trip: AP (must keep working)
â”œâ”€â”€ Local matching
â”œâ”€â”€ Local state management
â””â”€â”€ Queue for sync

Payment Processing: CP (must be accurate)
â”œâ”€â”€ Hold payment when matched (auth)
â”œâ”€â”€ Charge only after trip confirmed
â””â”€â”€ If conflict: refund the cancelled match

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Trip State Machine                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  REQUESTED â”€â”€â–º MATCHED â”€â”€â–º EN_ROUTE â”€â”€â–º IN_PROGRESS â”€â”€â–º END â”‚
â”‚     â”‚            â”‚                           â”‚              â”‚
â”‚   [Local]     [Local]                     [Local]           â”‚
â”‚     â”‚            â”‚                           â”‚              â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                          â”‚                                  â”‚
â”‚                     After partition:                        â”‚
â”‚                     Sync & reconcile                        â”‚
â”‚                          â”‚                                  â”‚
â”‚                    COMPLETED â”€â”€â–º PAYMENT (CP)               â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Summary:**

```
Decision: AP (Continue Service)

Justification:
1. Core business requires availability
2. Users have zero tolerance for downtime
3. Competitors are one tap away
4. Regional affinity prevents most conflicts
5. Conflict resolution handles edge cases
6. Payment can be CP (processed after trip)

Trade-off:
- ~0.1% of rides might need re-matching after partition
- Compensation: priority re-match + potential credit
- Better than 100% of users seeing errors!
```

</details>

---

## Next Up

Congratulations on completing Week 4: Distribution Basics! You now understand consistent hashing, message queues, and the fundamental CAP theorem trade-offs.

In Week 5, we'll dive into **System Design Patterns** starting with **Microservices vs Monoliths** - learning when to break apart your system and when to keep it together!
